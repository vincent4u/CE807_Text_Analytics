{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vincent4u/CE807_Text_Analytics/blob/main/lab08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6oqGiIXvrMl"
      },
      "source": [
        "# Lab 08- Building blocks of NN\n",
        "\n",
        "In this notebook, we work on a toy NLP task. Following resources have been used in preparation of this notebook:\n",
        "* [\"Word Window Classification\" tutorial notebook](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1204/materials/ww_classifier.ipynb) by Matt Lamm, from Winter 2020 offering of CS224N\n",
        "* Official PyTorch Documentation on [Deep Learning with PyTorch: A 60 Minute Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) by Soumith Chintala\n",
        "* PyTorch Tutorial Notebook, [Build Basic Generative Adversarial Networks (GANs) | Coursera](https://www.coursera.org/learn/build-basic-generative-adversarial-networks-gans) by Sharon Zhou, offered on Coursera\n",
        "* Official PyTorch Sentiment Analysis [Tutorial](https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html)\n",
        "\n",
        "Before starting copy the `lab08.ipynb` into your GDrive in `CE807-24-SP/Lab08/` and copy [`train,csv`, `valid.csv`, `test.csv`] from the `lab05`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0ukr7quvrMx"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Import pprint, module we use for making our print statements prettier\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k10ZRdcBwDP3"
      },
      "source": [
        "We are all set to start our tutorial. Let's dive in!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYLWqKIoaOyd"
      },
      "source": [
        "## Neural Network Module\n",
        "\n",
        "So far we have looked into the tensors, their properties and basic operations on tensors. We will use predefined blocks in the `torch.nn` module of `PyTorch`. We will then put together these blocks to create complex networks. Let's start by importing this module with an alias so that we don't have to type `torch` every time we use it.\n",
        "\n",
        "Think NN as Lego block and we will see different lego blocks and how to combine it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUmrDpbhV4Tn"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joGvRWjEbak0"
      },
      "source": [
        "### **Linear Layer**\n",
        "We can use `nn.Linear(H_in, H_out)` to create a a linear layer. This will take a matrix of `(N, *, H_in)` dimensions and output a matrix of `(N, *, H_out)`. The `*` denotes that there could be arbitrary number of dimensions in between. The linear layer performs the operation `Ax+b`, where `A` and `b` are initialized randomly. If we don't want the linear layer to learn the bias parameters, we can initialize our layer with `bias=False`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XfnKI4-a5j9",
        "outputId": "55d52fd8-5e3d-4cde-86e9-4b5bf847d303"
      },
      "source": [
        "# Create the inputs\n",
        "input = torch.ones(2,3,4)\n",
        "# N* H_in -> N*H_out\n",
        "\n",
        "\n",
        "# Make a linear layers transforming N,*,H_in dimensinal inputs to N,*,H_out\n",
        "# dimensional outputs\n",
        "linear = nn.Linear(4, 2)\n",
        "linear_output = linear(input)\n",
        "print(input.shape)\n",
        "print(linear_output.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 4])\n",
            "torch.Size([2, 3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ3on5dMGl9_",
        "outputId": "b1045b7e-6e0c-4c40-89a4-2341e0a7d5c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1677, -0.1773],\n",
              "         [ 0.1677, -0.1773],\n",
              "         [ 0.1677, -0.1773]],\n",
              "\n",
              "        [[ 0.1677, -0.1773],\n",
              "         [ 0.1677, -0.1773],\n",
              "         [ 0.1677, -0.1773]]], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_9XKtAFYpdI",
        "outputId": "6e3e7813-215d-4b84-cb29-a67166d51499"
      },
      "source": [
        "list(linear.parameters()) #y =  Wx + b"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.1725, -0.2027,  0.2013,  0.4770],\n",
              "         [-0.0294, -0.4212,  0.4194, -0.3759]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.1354,  0.2298], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data of shape [batch_size, feature_dim] # 4\n",
        "[batch_size, output_dim] # 2\n",
        "\n",
        "linear layer of shape (feature_dim, output_dim)"
      ],
      "metadata": {
        "id": "4JC4UEc6DugH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAXCCu9keUlW"
      },
      "source": [
        "### **Other Module Layers**\n",
        "There are several other preconfigured layers in the `nn` module. Some commonly used examples are `nn.RNN`. `nn.LSTM`, `nn.Transformer`, `nn.embedding`, `nn.dropout`, `nn.Conv2d`, `nn.ConvTranspose2d`, `nn.BatchNorm1d`, `nn.BatchNorm2d`, `nn.Upsample` and `nn.MaxPool2d` among many others. You should explore these. For now, the only important thing to remember is that we can treat each of these layers as plug and play components."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yslDOK66fYWn"
      },
      "source": [
        "### **Activation Function Layer**\n",
        "We can also use the `nn` module to apply activations functions to our tensors. Activation functions are used to add non-linearity to our network. Some examples of activations functions are `nn.ReLU()`, `nn.Sigmoid()` and `nn.LeakyReLU()`. Activation functions operate on each element seperately, so the shape of the tensors we get as an output are the same as the ones we pass in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrJP5CveeOON",
        "outputId": "b9eb5757-45e0-42f6-9093-1969869fa0f5"
      },
      "source": [
        "linear_output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.5352, 1.0476],\n",
              "         [0.5352, 1.0476],\n",
              "         [0.5352, 1.0476]],\n",
              "\n",
              "        [[0.5352, 1.0476],\n",
              "         [0.5352, 1.0476],\n",
              "         [0.5352, 1.0476]]], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9v5FjQtd4Ck",
        "outputId": "21ddbc08-1d84-4f4c-ce58-86b136ede0a5"
      },
      "source": [
        "sigmoid = nn.Sigmoid()\n",
        "output = sigmoid(linear_output)\n",
        "output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.3065, 0.4799],\n",
              "         [0.3065, 0.4799],\n",
              "         [0.3065, 0.4799]],\n",
              "\n",
              "        [[0.3065, 0.4799],\n",
              "         [0.3065, 0.4799],\n",
              "         [0.3065, 0.4799]]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiYTthJwhEYT"
      },
      "source": [
        "### **Putting the Layers Together**\n",
        "So far we have seen that we can create layers and pass the output of one as the input of the next. Instead of creating intermediate tensors and passing them around, we can use `nn.Sequentual`, which does exactly that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtJeOqLxhBLY",
        "outputId": "d0071a3d-bbf4-46be-f5e9-239c1fcde1e2"
      },
      "source": [
        "block = nn.Sequential(\n",
        "    nn.Linear(4, 2),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "input = torch.ones(2,3,4)\n",
        "output = block(input)\n",
        "output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.6765, 0.2957],\n",
              "         [0.6765, 0.2957],\n",
              "         [0.6765, 0.2957]],\n",
              "\n",
              "        [[0.6765, 0.2957],\n",
              "         [0.6765, 0.2957],\n",
              "         [0.6765, 0.2957]]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkJ81p3GUVPM"
      },
      "source": [
        "### Custom Modules\n",
        "\n",
        "Instead of using the predefined modules, we can also build our own by extending the `nn.Module` class. For example, we can build a the `nn.Linear` (which also extends `nn.Module`) on our own using the tensor introduced earlier! We can also build new, more complex modules, such as a custom neural network. You will be practicing these in the later assignment.\n",
        "\n",
        "To create a custom module, the first thing we have to do is to extend the `nn.Module`. We can then initialize our parameters in the `__init__` function, starting with a call to the `__init__` function of the super class. All the class attributes we define which are `nn` module objects are treated as parameters, which can be learned during the training. Tensors are not parameters, but they can be turned into parameters if they are wrapped in `nn.Parameter` class.\n",
        "\n",
        "All classes extending `nn.Module` are also expected to implement a `forward(x)` function, where `x` is a tensor. This is the function that is called when a parameter is passed to our module, such as in `model(x)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2P7eZiMj32_"
      },
      "source": [
        "class MultilayerPerceptron(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    # Call to the __init__ function of the super class\n",
        "    super(MultilayerPerceptron, self).__init__()\n",
        "\n",
        "    # Bookkeeping: Saving the initialization parameters\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    # Defining of our model\n",
        "    # There isn't anything specific about the naming of `self.model`. It could\n",
        "    # be something arbitrary.\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(self.input_size, self.hidden_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(self.hidden_size, self.output_size),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.model(x)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2DrfLiBVjNT"
      },
      "source": [
        "Here is an alternative way to define the same class. You can see that we can replace `nn.Sequential` by defining the individual layers in the `__init__` method and connecting the in the `forward` method.\n",
        "\n",
        "**You should look explore this on your time. We will not use that for now. Very useful for later.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-lqhsqwViIk"
      },
      "source": [
        "class MultilayerPerceptronOther(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    # Call to the __init__ function of the super class\n",
        "    super(MultilayerPerceptronOther, self).__init__()\n",
        "\n",
        "    # Bookkeeping: Saving the initialization parameters\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    # Defining of our layers\n",
        "    self.linear = nn.Linear(self.input_size, self.hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(self.hidden_size, self.input_size)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    linear = self.linear(x)\n",
        "    relu = self.relu(linear)\n",
        "    linear2 = self.linear2(relu)\n",
        "\n",
        "    output = self.sigmoid(linear2)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQelcFo5bXgU"
      },
      "source": [
        "Now that we have defined our class, we can instantiate it and see what it does."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXi0T0FZbV0y",
        "outputId": "d044624c-6bfa-4c22-9edb-1e36942285bf"
      },
      "source": [
        "# Make a sample input\n",
        "input = torch.randn(2, 5)\n",
        "\n",
        "# Create our model\n",
        "model = MultilayerPerceptronOther(5, 3)\n",
        "\n",
        "# view your model\n",
        "print(model)\n",
        "\n",
        "# Pass our input through our model\n",
        "model(input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultilayerPerceptronOther(\n",
            "  (linear): Linear(in_features=5, out_features=3, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (linear2): Linear(in_features=3, out_features=5, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5689, 0.3883, 0.5454, 0.4766, 0.6265],\n",
              "        [0.5689, 0.3883, 0.5454, 0.4766, 0.6265]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCCbjc-Fb2-B"
      },
      "source": [
        "We can inspect the parameters of our model with `named_parameters()` and `parameters()` methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d23soYIb2WZ",
        "outputId": "5b103583-3d67-45ea-ddf9-29ea29951be7"
      },
      "source": [
        "list(model.named_parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('linear.weight',\n",
              "  Parameter containing:\n",
              "  tensor([[ 0.1669,  0.4012,  0.3640, -0.0566, -0.1038],\n",
              "          [ 0.2690,  0.2314, -0.0324,  0.2108,  0.2875],\n",
              "          [-0.4431,  0.2409,  0.1235,  0.3086, -0.0587]], requires_grad=True)),\n",
              " ('linear.bias',\n",
              "  Parameter containing:\n",
              "  tensor([-0.3627, -0.4058, -0.1792], requires_grad=True)),\n",
              " ('linear2.weight',\n",
              "  Parameter containing:\n",
              "  tensor([[-0.3140,  0.4077,  0.5668],\n",
              "          [ 0.3105,  0.1851, -0.2556],\n",
              "          [-0.4679, -0.2095,  0.2674],\n",
              "          [-0.1784, -0.2849,  0.0854],\n",
              "          [-0.3173,  0.2270, -0.0974]], requires_grad=True)),\n",
              " ('linear2.bias',\n",
              "  Parameter containing:\n",
              "  tensor([ 0.2774, -0.4544,  0.1819, -0.0936,  0.5174], requires_grad=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5JegycOdMFy"
      },
      "source": [
        "### Optimization\n",
        "We have showed how gradients are calculated with the `backward()` function. Having the gradients isn't enought for our models to learn. We also need to know how to update the parameters of our models. This is where the optomozers comes in. `torch.optim` module contains several optimizers that we can use. Some popular examples are `optim.SGD` and `optim.Adam`. When initializing optimizers, we pass our model parameters, which can be accessed with `model.parameters()`, telling the optimizers which values it will be optimizing. Optimizers also has a learning rate (`lr`) parameter, which determines how big of an update will be made in every step. Different optimizers have different hyperparameters as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0F-TvV0kk-I"
      },
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgak6o5dlQWF"
      },
      "source": [
        "After we have our optimization function, we can define a `loss` that we want to optimize for. We can either define the loss ourselves, or use one of the predefined loss function in `PyTorch`, such as `nn.BCELoss()`. Let's put everything together now! We will start by creating some dummy data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGYFiaT_vXBn",
        "outputId": "9d753073-d749-4abf-bcf0-cc3f4a1b1ad5"
      },
      "source": [
        "# Create the y data\n",
        "y = torch.ones(10, 5)\n",
        "\n",
        "# Add some noise to our goal y to generate our x\n",
        "# We want out model to predict our original data, albeit the noise\n",
        "x = y + torch.randn_like(y)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.9701e-01, -6.1885e-01,  1.6636e+00,  2.1120e-01,  1.3613e+00],\n",
              "        [ 1.2594e+00, -1.3167e+00,  1.2603e+00,  1.1917e+00,  4.0456e-01],\n",
              "        [ 2.0414e+00,  1.3086e+00,  3.0286e+00,  4.5643e-01,  1.7493e+00],\n",
              "        [ 1.6499e+00, -1.0086e+00,  2.3947e-03,  1.3789e+00,  1.8033e+00],\n",
              "        [ 1.9085e+00,  8.8946e-01,  1.9690e+00,  1.5673e+00,  7.5319e-01],\n",
              "        [ 2.1733e-01, -2.0131e+00,  7.7295e-01,  1.9829e-01,  1.1492e+00],\n",
              "        [-4.5213e-01, -8.6100e-01,  1.5477e+00,  1.5609e+00,  5.0707e-01],\n",
              "        [ 3.4678e+00,  1.7280e-01,  1.3166e+00,  1.0527e+00,  9.8280e-01],\n",
              "        [ 1.2958e-01,  1.3651e-01,  4.7373e-01,  2.4982e+00, -1.1708e-02],\n",
              "        [ 1.1763e+00, -6.2523e-02,  1.5582e+00,  1.2180e+00,  7.4713e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEsiOdpWvfLj"
      },
      "source": [
        "Now, we can define our model, optimizer and the loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oA2XsdsbN8p",
        "outputId": "ff9cf415-6b6a-42c6-d0b1-8635fa919f22"
      },
      "source": [
        "# Instantiate the model\n",
        "model = MultilayerPerceptronOther(5, 3)\n",
        "\n",
        "# Define the optimizer\n",
        "adam = optim.Adam(model.parameters(), lr=1e-1)\n",
        "\n",
        "# Define loss using a predefined loss function\n",
        "loss_function = nn.BCELoss()\n",
        "\n",
        "# Calculate how our model is doing now\n",
        "y_pred = model(x)\n",
        "loss_function(y_pred, y).item()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7915621995925903"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtxU7Y8ZufSR"
      },
      "source": [
        "Let's see if we can have our model achieve a smaller loss. Now that we have everything we need, we can setup our training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogl6-Ctmuek6",
        "outputId": "41a80842-ff35-465b-8b55-e5d3d5092301"
      },
      "source": [
        "# Set the number of epoch, which determines the number of training iterations\n",
        "n_epoch = 10\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "  # Set the gradients to 0\n",
        "  adam.zero_grad()\n",
        "\n",
        "  # Get the model predictions\n",
        "  y_pred = model(x)\n",
        "\n",
        "  # Get the loss\n",
        "  loss = loss_function(y_pred, y)\n",
        "\n",
        "  # Print stats\n",
        "  print(f\"Epoch {epoch}: traing loss: {loss}\")\n",
        "\n",
        "  # Compute the gradients\n",
        "  loss.backward()\n",
        "\n",
        "  # Take a step to optimize the weights\n",
        "  adam.step()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: traing loss: 0.7915621995925903\n",
            "Epoch 1: traing loss: 0.6754158139228821\n",
            "Epoch 2: traing loss: 0.5232229828834534\n",
            "Epoch 3: traing loss: 0.3394404351711273\n",
            "Epoch 4: traing loss: 0.18138450384140015\n",
            "Epoch 5: traing loss: 0.08172585815191269\n",
            "Epoch 6: traing loss: 0.03219425305724144\n",
            "Epoch 7: traing loss: 0.011801823042333126\n",
            "Epoch 8: traing loss: 0.004278777167201042\n",
            "Epoch 9: traing loss: 0.0015957721043378115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nXApd82wlsF"
      },
      "source": [
        "You can see that our loss is decreasing. Let's check the predictions of our model now and see if they are close to our original `y`, which was all `1s`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrMJ8AmqeCY-",
        "outputId": "af44ee54-c6b3-4ba0-a3a8-d855b6ce79bc"
      },
      "source": [
        "list(model.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.8992, -1.1627,  0.7044,  0.5427,  0.4928],\n",
              "         [ 0.7942, -1.0633,  0.9726,  0.8489,  0.1308],\n",
              "         [-0.4300,  0.0975, -0.2691, -0.3832,  0.1093]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.7234,  0.6621, -0.0710], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[1.1843, 0.5509, 0.0725],\n",
              "         [0.8452, 0.7392, 0.1514],\n",
              "         [1.0439, 1.2031, 0.8025],\n",
              "         [1.3871, 0.7795, 0.3933],\n",
              "         [1.2533, 1.0782, 0.9255]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.7199, 0.3024, 1.1683, 0.5895, 0.4554], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRqE7P9EtvuS",
        "outputId": "cf0c8489-1650-4419-c03e-1b0b9e47c22f"
      },
      "source": [
        "# See how our model performs on the training data\n",
        "y_pred = model(x)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9990, 0.9972, 0.9999, 0.9997, 0.9998],\n",
              "        [0.9999, 0.9998, 1.0000, 1.0000, 1.0000],\n",
              "        [0.9997, 0.9993, 1.0000, 1.0000, 1.0000],\n",
              "        [0.9999, 0.9996, 1.0000, 1.0000, 1.0000],\n",
              "        [0.9997, 0.9992, 1.0000, 0.9999, 1.0000],\n",
              "        [0.9997, 0.9992, 1.0000, 1.0000, 1.0000],\n",
              "        [0.9992, 0.9982, 0.9999, 0.9998, 0.9999],\n",
              "        [1.0000, 0.9999, 1.0000, 1.0000, 1.0000],\n",
              "        [0.9950, 0.9907, 0.9994, 0.9983, 0.9990],\n",
              "        [0.9996, 0.9989, 1.0000, 0.9999, 1.0000]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJng31_Pi2R6",
        "outputId": "a0af892d-2923-457f-b7e7-0c8f48e7fc66"
      },
      "source": [
        "# Create test data and check how our model performs on it\n",
        "x2 = y + torch.randn_like(y)\n",
        "y_pred = model(x2)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9787, 0.9761, 0.9775, 0.9796, 0.8904],\n",
              "        [0.9797, 0.9984, 0.9994, 0.9923, 0.9910],\n",
              "        [0.9984, 1.0000, 1.0000, 0.9998, 0.9998],\n",
              "        [0.9908, 0.9995, 0.9999, 0.9972, 0.9962],\n",
              "        [0.9939, 0.9998, 0.9999, 0.9984, 0.9979],\n",
              "        [0.9868, 0.9993, 0.9998, 0.9958, 0.9954],\n",
              "        [0.9863, 0.9993, 0.9998, 0.9956, 0.9951],\n",
              "        [0.9962, 0.9997, 0.9999, 0.9986, 0.9959],\n",
              "        [0.9695, 0.9964, 0.9985, 0.9862, 0.9831],\n",
              "        [0.9648, 0.9951, 0.9979, 0.9831, 0.9789]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WNk6oIZw2xo"
      },
      "source": [
        "Great! Looks like our model almost perfectly learned to filter out the noise from the `x` that we passed in!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8rUNk_1xG1v"
      },
      "source": [
        "# Text Classification\n",
        "\n",
        "Until this part of the notebook, we have learned the fundamentals of PyTorch and built a basic network solving a toy dataset. Now we will attempt to solve sentiment analysis, we will use part of IMDB dataset https://www.kaggle.com/datasets/columbine/imdb-dataset-sentiment-analysis-in-csv-format.\n",
        "\n",
        "Here are the things we will learn:\n",
        "\n",
        "1. Data: Creating a Dataset of Batched Tensors\n",
        "2. Modeling\n",
        "3. Training\n",
        "4. Prediction\n",
        "\n",
        "In this section, our goal will be to train a model that will predict the sentiment of a sentence, called `Sentiment Classification`.\n",
        "\n",
        "Let's dive in!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_amzuUx8BJXI"
      },
      "source": [
        "## Data\n",
        "\n",
        "In NLP tasks, the corpus would generally be a `.txt`, `.json` or `.csv` file where each row corresponds to a sentence or a tabular datapoint. We are using `.csv` format.\n",
        "\n",
        "Before we start working on the code, let's mount the Gdrive and get path of the GDrive. Make sure that you have all files in the `Lab07` folder."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "D-TAf39IQcIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "id": "NuQL6BKKQc_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6d76788-c2b3-4eb3-e899-93e6b1230717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# TODO: Fill in the Google Drive path where you uploaded the assignment\n",
        "# Example: If you create a 2020FA folder and put all the files under Lab07 folder\n",
        "# GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'Lab08'\n",
        "GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = './CE807-24-SP/Lab08/'\n",
        "GOOGLE_DRIVE_PATH = os.path.join('gdrive', 'MyDrive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
        "GOOGLE_DRIVE_DATA_PATH = os.path.join(GOOGLE_DRIVE_PATH, 'data')\n",
        "print(os.listdir(GOOGLE_DRIVE_PATH))\n",
        "print(os.listdir(GOOGLE_DRIVE_DATA_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft7By6hlQznA",
        "outputId": "c3427dc5-d416-481e-90e6-9fdd600f9b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['lab08.ipynb', 'data']\n",
            "['valid.csv', 'train.csv', 'test.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note the from last lab, instead of coping files in the current working directory, we are using semi-automatically getting the PATH and adding PATH in the while reading the files. This reduces the coping time.**"
      ],
      "metadata": {
        "id": "PJbucR8bfroJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDiI1PLMw10z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5600421-3df0-4d7b-b929-e8582183fce1"
      },
      "source": [
        "# Let's read the train file\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "train_file = os.path.join(GOOGLE_DRIVE_DATA_PATH, 'train.csv')\n",
        "train_data = pd.read_csv(train_file)\n",
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head(100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "vmwig_WoRWcC",
        "outputId": "627c742a-4fde-4e9f-c5d3-d104a753a434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 text  label\n",
              "0   I grew up (b. 1965) watching and loving the Th...      0\n",
              "1   When I put this movie in my DVD player, and sa...      0\n",
              "2   Why do people who do not know what a particula...      0\n",
              "3   Even though I have great interest in Biblical ...      0\n",
              "4   Im a die hard Dads Army fan and nothing will e...      1\n",
              "..                                                ...    ...\n",
              "95  ...I saw this movie when it first came out in ...      1\n",
              "96  Released in December of 1957, Sayonara went on...      1\n",
              "97  War, Inc. - Corporations take over war in the ...      0\n",
              "98  What is your freaking problem? Do you have not...      1\n",
              "99  Dick and Jane Harper (Jim Carrey, Téa Leoni) w...      0\n",
              "\n",
              "[100 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f32aa3f1-124a-48e4-bfac-6d97e578453b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When I put this movie in my DVD player, and sa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why do people who do not know what a particula...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Even though I have great interest in Biblical ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>...I saw this movie when it first came out in ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Released in December of 1957, Sayonara went on...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>War, Inc. - Corporations take over war in the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>What is your freaking problem? Do you have not...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Dick and Jane Harper (Jim Carrey, Téa Leoni) w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f32aa3f1-124a-48e4-bfac-6d97e578453b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f32aa3f1-124a-48e4-bfac-6d97e578453b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f32aa3f1-124a-48e4-bfac-6d97e578453b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3ca413d7-c2d3-4ca4-b504-d2987130924a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3ca413d7-c2d3-4ca4-b504-d2987130924a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3ca413d7-c2d3-4ca4-b504-d2987130924a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 40000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39723,\n        \"samples\": [\n          \"There are similarities between Ray Lawrence's \\\"Jindabyne\\\" and his last movie \\\"Lantana\\\" \\u0096 a dead body and its repercussions for already dysfunctional lives. But whereas \\\"Lantana\\\" offered some hope and resolution, \\\"Jindabyne\\\" leaves everything unresolved in a bleak way that will leave most viewers unsatisfied, perhaps even cheated.<br /><br />The storyline - the aftermath of a fisherman's discovery of a corpse floating in a remote river - is based on a short story by Raymond Carver. It became an element in Robert Altman's classic 1993 ensemble \\\"Short Cuts\\\". Lawrence uses this theme for an exploration and exposition of relationships within a small Australian community under stress. The movie poses some moral questions \\\"Would you let the discovery of a dead body ruin your good weekend?\\\" and more poignantly for Australians \\\"Would it make any difference if the dead person was an aboriginal?\\\" The acting, especially by Gabriel Byrne and Laura Linney, is commendable. And there are elements of mysticism reinforced by haunting music, not unlike \\\"Picnic at Hanging Rock\\\".<br /><br />If all this sounds like the basis for a great movie - be prepared for a let down, the pace is very slow and the murder is shown near the beginning, thereby eliminating the element of mystery. And so we are left with these desolate lives and a blank finale.\",\n          \"Hammer House of Horror: Witching Time is set in rural England on Woodstock farm where stressed musician David Winter (Jon Finch) lives with his actress wife Mary (Prunella Gee) & is currently composing the music for a horror film. One night while looking for his dog Billy David finds a mysterious woman in his barn, calling herself Lucinda Jessop (Patricia Quinn) she claims to be a witch who has transported herself from 300 years in the past to now. Obviously rather sceptical David has a hard time believing her so he locks her in a room in his farmhouse & calls his doctor Charles (Ian McCulloch) to come examine her, however once he arrives & they enter the room Lucinda has disappeared. Charles puts it down to David drinking too much but over the next few day strange & disturbing things begin to happen to David & Mary...<br /><br />Witching Time was episode 1 from the short lived British anthology horror series produced by Hammer studios for TV & originally aired here in the UK during September 1980, the first of two Hammer House of Horror episodes to be directed by Don Leaver (episode 13 The Mark of Satan being the other) I actually rather liked this. As a series Hammer House of Horror dealt with various different themes & were all unconnected to each other except in name & unsurprisingly Watching Time is a sinister & effective little tale about a witch, the script by Anthony Read benefits from it's slight 50 odd minute duration & moves along at a nice pace. The character's are pretty good as is the dialogue, there are some nice scenes here & I liked the way it never quite reveals whether David & Mary are going crazy or not. I think it's a well structured, entertaining & reasonably creepy horror themed TV show that I enjoyed more than I thought I would.<br /><br />Being made for British TV meant the boys at Hammer had a lower budget than usual, if that was even possible, & as such there is no gorgeous period settings here as in their most well know Frankenstein & Dracula films although the contemporary English setting does give it a certain atmosphere that you can relate to a bit more. Another TV based restriction is that the exploitation levels are lower than you might hope for, there's some nudity & gore but not much although I didn't mind too much as the story here is pretty good. It's well made for what it is & Hammer's experience on their feature films probably helped make these look pretty good, the acting is good as well with genre favourite Ian McCulloch making a bit-part appearance.<br /><br />Witching Time is a good start to the Hammer House of Horror series, as a 50 minute piece of British TV it's pretty damned good, now why don't they make show's like this over here anymore?\",\n          \"What a great cast for this movie. The timing was excellent and there were so many clever lines-several times I was still laughing minutes after they were delivered. I found Manna From Heaven to have some surprising moments and while there were things I was thinking would happen, the way they came together was anything but predictable. This movie is about hope and righting wrongs. I left the theater feeling inspired to do the right thing. Bravo to the Five Sisters.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For sake of simplicity let's use only 10% data points\n",
        "train_data = train_data.sample(frac=0.1).reset_index(drop=True) # Shuffling and selecting 10% of data\n",
        "train_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_xNpfhhRf8S",
        "outputId": "a92bc353-9e81-4aec-c15b-d37f5f2a9851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t33Uke9AE22s"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "To make it easier for our models to learn, we usually apply a few preprocessing steps to our data. This is especially important when dealing with text data. Here are some examples of text preprocessing:\n",
        "* **Tokenization**: Tokenizing the sentences into words.\n",
        "* **Lowercasing**: Changing all the letters to be lowercase.\n",
        "* **Noise removal:** Removing special characters (such as punctuations).\n",
        "* **Stop words removal**: Removing commonly used words.\n",
        "\n",
        "Which preprocessing steps are necessary is determined by the task at hand. For example, although it is useful to remove special characters in some tasks, for others they may be important (for example, if we are dealing with multiple languages). For our task, we will lowercase our words and tokenize.\n",
        "\n",
        "**We are not going to apply any preprocessing steps. You should explore which steps in needed.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTGn8ANTzZXT"
      },
      "source": [
        "import numpy\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer = CountVectorizer(stop_words='english',max_features=5000)\n",
        "train_values = count_vectorizer.fit_transform(train_data['text'].values)\n",
        "train_labels = train_data['label'].values"
      ],
      "metadata": {
        "id": "rcyK5nPsSeR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_values), type(train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xtw6D_owS8YV",
        "outputId": "35392aac-ed65-497c-d5e0-14b5a547ffe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(scipy.sparse._csr.csr_matrix, numpy.ndarray)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch needs data into the `Tensor`. Let's convert it.\n",
        "Remember, text representation (here, Conunt Vectorized) needs to be in `float` and label in `int` format."
      ],
      "metadata": {
        "id": "h7zoCj3onukX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_values = torch.tensor(train_values.toarray()).float()\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n"
      ],
      "metadata": {
        "id": "-g-69BogTI1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batching Sentences\n",
        "\n",
        "We have learned about batches in class. Waiting our whole training corpus to be processed before making an update is constly. On the other hand, updating the parameters after every training example causes the loss to be less stable between updates. To combat these issues, we instead update our parameters after training on a batch of data. This allows us to get a better estimate of the gradient of the global loss. In this section, we will learn how to structure our data into batches using the `torch.util.data.DataLoader` class.\n",
        "\n",
        "We will be calling the `DataLoader` class as follows: `DataLoader(data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)`.  The `batch_size` parameter determines the number of examples per batch. In every epoch, we will be iterating over all the batches using the `DataLoader`. The order of batches is deterministic by default, but we can ask `DataLoader` to shuffle the batches by setting the `shuffle` parameter to `True`. This way we ensure that we don't encounter a bad batch multiple times.\n",
        "\n",
        "**Note:** We are not exploring `collate_fn` you must explore that. It would be very useful and needed in the excercise/next labs.\n",
        "\n",
        "If provided, `DataLoader` passes the batches it prepares to the `collate_fn`. We can write a custom function to pass to the `collate_fn` parameter in order to print stats about our batch or perform extra processing. In our case, we will not use the `collate_fn`, you should explore how `collate_fn` works and will be useful in the following labs."
      ],
      "metadata": {
        "id": "GzoSMsZvT8Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "tQbEsJdYKJge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(train_values, train_labels)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8,shuffle=True)"
      ],
      "metadata": {
        "id": "2l4FGtsQS2SB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KeSTKqY9JeWN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4jzo5tp0Hza"
      },
      "source": [
        "For each training example we have, we should also have a corresponding sentiment label. Recall that the goal of our model was to determine sentiment of a give sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS1WuQO0Khxx"
      },
      "source": [
        "Now, we can see the `DataLoader` in action."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, batch in enumerate(train_loader):\n",
        "  inputs = batch[0]\n",
        "  labels = batch[1]\n",
        "  print(i,inputs.shape, labels.shape)\n",
        "\n",
        "  print(\"Batched Input:\")\n",
        "  print(inputs)\n",
        "  print(\"Batched Labels:\")\n",
        "  print(labels)\n",
        "\n",
        "  # Let's see only 3 batchs\n",
        "  if i > 3:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOvcAQP5UlOV",
        "outputId": "86f09d4a-1a3a-4a33-b69b-7bc5a26fd031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([8, 5000]) torch.Size([8])\n",
            "Batched Input:\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "Batched Labels:\n",
            "tensor([1, 1, 1, 1, 1, 0, 0, 0])\n",
            "1 torch.Size([8, 5000]) torch.Size([8])\n",
            "Batched Input:\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "Batched Labels:\n",
            "tensor([0, 1, 0, 0, 1, 0, 1, 0])\n",
            "2 torch.Size([8, 5000]) torch.Size([8])\n",
            "Batched Input:\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "Batched Labels:\n",
            "tensor([0, 0, 0, 1, 0, 1, 1, 0])\n",
            "3 torch.Size([8, 5000]) torch.Size([8])\n",
            "Batched Input:\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "Batched Labels:\n",
            "tensor([0, 1, 1, 0, 1, 1, 1, 0])\n",
            "4 torch.Size([8, 5000]) torch.Size([8])\n",
            "Batched Input:\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.]])\n",
            "Batched Labels:\n",
            "tensor([1, 1, 0, 1, 1, 1, 0, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The batched input tensors you see above will be passed into our model."
      ],
      "metadata": {
        "id": "Gt6SsvocVR2g"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlDbOpeoSKxd"
      },
      "source": [
        "## Model\n",
        "\n",
        "Now that we have prepared our data, we are ready to build our model. We have learned how to write custom `nn.Module` classes. We will do the same here and put everything we have learned so far together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLTU4h76NLYm"
      },
      "source": [
        "class MultilayerPerceptron(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    # Call to the __init__ function of the super class\n",
        "    super(MultilayerPerceptron, self).__init__()\n",
        "\n",
        "    # Bookkeeping: Saving the initialization parameters\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    # Defining of our model\n",
        "    # There isn't anything specific about the naming of `self.model`. It could\n",
        "    # be something arbitrary.\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(self.input_size, self.hidden_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(self.hidden_size, self.output_size),\n",
        "\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.model(x)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to perform processing on the GPU, so let's check we have GPU access or not. If output is `cpu`, go to `RunTime` and change it to `GPU`"
      ],
      "metadata": {
        "id": "pC6LHma3ZEB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilt8DiqQLYS1",
        "outputId": "81859a92-63a5-43e5-d348-027443729c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Avy1fnyAvEcd"
      },
      "source": [
        "## Training\n",
        "\n",
        "We are now ready to put everything together. Let's start with preparing our data and intializing our model. We can then intialize our optimizer and define our loss function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(PATH, file_name, sample_flag=False,count_vectorizer=None):\n",
        "  # Prepare the data\n",
        "  file_path = os.path.join(PATH, file_name)\n",
        "  data = pd.read_csv(file_path)\n",
        "  if sample_flag:\n",
        "    # For sake of simplicity let's use only 10% data points\n",
        "    data = data.sample(frac=0.1).reset_index(drop=True) # Shuffling dataset\n",
        "\n",
        "  if count_vectorizer == None:\n",
        "    count_vectorizer = CountVectorizer(stop_words='english',max_features=5000)\n",
        "    values = count_vectorizer.fit_transform(data['text'].values) #TODO: This is the best way to do this, because you need to use same vectorization menthod\n",
        "  else:\n",
        "    values = count_vectorizer.transform(data['text'].values)\n",
        "\n",
        "  labels = data['label'].values\n",
        "\n",
        "  # Convert into Tensor\n",
        "  values = torch.tensor(values.toarray()).float()\n",
        "  labels = torch.tensor(labels)\n",
        "\n",
        "  dataset = TensorDataset(values, labels)\n",
        "  input_size = values.shape[1]\n",
        "  return dataset, input_size, count_vectorizer"
      ],
      "metadata": {
        "id": "rwx_kx0tiM2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHxpxDkFHfQE"
      },
      "source": [
        "Unlike our earlier example, this time instead of passing all of our training data to the model at once in each epoch, we will be utilizing batches. Hence, in each training epoch iteration, we also iterate over the batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bInu1VqjHsfj"
      },
      "source": [
        "train_dataset, input_size, count_vectorizer = prepare_dataset(GOOGLE_DRIVE_DATA_PATH, 'train.csv',sample_flag=True)\n",
        "\n",
        "batch_size = 256\n",
        "shuffle = True\n",
        "\n",
        "# Instantiate a DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size,shuffle=shuffle) # In training always make shuffle True\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we initialize the Model and Optimizers"
      ],
      "metadata": {
        "id": "H0UYyVTNXLDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of Epochs\n",
        "epochs = 5\n",
        "\n",
        "# Define loss using a predefined loss function\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialize a model\n",
        "input_size = input_size # TODO: This needs to be automatically get using the train dataset\n",
        "hidden_size = 5000\n",
        "output_size = 2 # TODO: This needs to be automatically get using the train dataset\n",
        "\n",
        "model = MultilayerPerceptron(input_size=input_size,hidden_size=hidden_size, output_size=output_size )\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the optimizer\n",
        "lr = 3e-4\n",
        "# Remember your optimizer has to come after model definition\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n"
      ],
      "metadata": {
        "id": "Nn9e0EEtXKIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could print the model to see it's *structure*"
      ],
      "metadata": {
        "id": "n1P2V4JQXdpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V3ay5ZxXkMe",
        "outputId": "0af2e4bc-4026-445e-a783-5bf368b844a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultilayerPerceptron(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=5000, out_features=5000, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=5000, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could print the model to see it's *parameters*"
      ],
      "metadata": {
        "id": "TFnK6yb9idRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(model.named_parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cgTOIoLif7x",
        "outputId": "9e368a82-c5d2-43d1-db8e-20c09d184abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('model.0.weight', Parameter containing:\n",
              "  tensor([[-4.5964e-03,  1.0675e-03, -5.2198e-04,  ...,  3.2820e-03,\n",
              "           -3.8510e-03,  1.0303e-04],\n",
              "          [ 3.1441e-03,  2.6863e-03, -1.7671e-03,  ...,  6.1005e-04,\n",
              "            3.1300e-03, -8.3220e-04],\n",
              "          [ 1.2263e-03,  2.0113e-03, -1.9841e-03,  ..., -1.9870e-03,\n",
              "           -4.4786e-03,  4.3131e-03],\n",
              "          ...,\n",
              "          [-2.9322e-03, -2.6344e-03,  8.4344e-04,  ...,  4.0358e-06,\n",
              "           -4.7841e-03, -1.1734e-03],\n",
              "          [ 3.0618e-03,  1.9057e-03, -4.5409e-03,  ...,  4.7796e-03,\n",
              "           -1.9344e-03, -2.9679e-03],\n",
              "          [-6.2538e-04, -4.1798e-03,  1.1348e-03,  ...,  1.5805e-03,\n",
              "           -1.6993e-03,  4.8536e-04]], device='cuda:0', requires_grad=True)),\n",
              " ('model.0.bias', Parameter containing:\n",
              "  tensor([ 5.9344e-05, -1.9122e-03, -6.6171e-04,  ...,  4.9184e-03,\n",
              "           4.7517e-03,  1.7212e-03], device='cuda:0', requires_grad=True)),\n",
              " ('model.2.weight', Parameter containing:\n",
              "  tensor([[-0.0086, -0.0024, -0.0022,  ..., -0.0065,  0.0013, -0.0057],\n",
              "          [-0.0110,  0.0110,  0.0087,  ..., -0.0109, -0.0003,  0.0081]],\n",
              "         device='cuda:0', requires_grad=True)),\n",
              " ('model.2.bias', Parameter containing:\n",
              "  tensor([-0.0134, -0.0083], device='cuda:0', requires_grad=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Contained 2 loops\n",
        "\n",
        "\n",
        "*   Batch Processing: Take one batch on input and update the model parameters\n",
        "*   Epoch Processing: All traning data needs to be processed `n` number of epochs\n",
        "\n",
        "In practice, we sum all loss in an epoch and monitor it in each epochs. In practice, our training loss decreases as training progresses.\n",
        "\n"
      ],
      "metadata": {
        "id": "Pg-9g7dDXpLV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL9IDgIOvHca"
      },
      "source": [
        "# Function that will be called in every epoch\n",
        "def train_epoch(loss_function, optimizer, model, data_loader):\n",
        "\n",
        "  # Keep track of the total loss for the batch\n",
        "  total_loss = 0\n",
        "  for i, batch in enumerate(data_loader):\n",
        "    # We could move whole data to GPU but it will take lots of space so only move one batch at a time\n",
        "    batch_inputs = batch[0].to(device)\n",
        "    batch_labels = batch[1].to(device)\n",
        "    # print(batch_inputs.shape)\n",
        "     # Clear the gradients\n",
        "    optimizer.zero_grad()\n",
        "    # Run a forward pass\n",
        "    outputs = model.forward(batch_inputs)\n",
        "    # Compute the batch loss\n",
        "    loss = loss_function(outputs, batch_labels)\n",
        "    # Calculate the gradients\n",
        "    loss.backward()\n",
        "    # Update the parameteres\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function containing our main training loop\n",
        "def train(loss_function, optimizer, model, data_loader, num_epochs=5):\n",
        "\n",
        "  # Iterate through each epoch and call our train_epoch function\n",
        "  for epoch in range(num_epochs):\n",
        "    epoch_loss = train_epoch(loss_function, optimizer, model, data_loader)\n",
        "    print('epoch_loss', epoch_loss)"
      ],
      "metadata": {
        "id": "J2ogTL3WsEzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjf75cnzJ4n6"
      },
      "source": [
        "Let's start training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kav8kwVBJ6XW",
        "outputId": "c089f13c-4c03-4a81-9ed9-96689736cbab"
      },
      "source": [
        "print('Start')\n",
        "# print(list(model.parameters()))\n",
        "\n",
        "train(loss_function, optimizer, model, train_loader, num_epochs=epochs)\n",
        "\n",
        "print('End')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start\n",
            "epoch_loss 9.243936866521835\n",
            "epoch_loss 4.392946869134903\n",
            "epoch_loss 2.181407205760479\n",
            "epoch_loss 1.0326011180877686\n",
            "epoch_loss 0.5059353373944759\n",
            "End\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-k7Pav4LdQJ"
      },
      "source": [
        "## Prediction\n",
        "\n",
        "Let's see how well our model is at making predictions. We can start by creating our test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v5X69a2Lkbm"
      },
      "source": [
        "# Load test Data\n",
        "test_dataset, c , _ = prepare_dataset(GOOGLE_DRIVE_DATA_PATH, 'test.csv',sample_flag=True,count_vectorizer=count_vectorizer)\n",
        "\n",
        "# Instantiate a DataLoader\n",
        "# in practice you need to keep shuffle false at the testing time, so that you could easily match data with predicted label\n",
        "test_loader = DataLoader(test_dataset, batch_size=8,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model in evaluation state\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXOF5o7DSY21",
        "outputId": "bbcbdc8e-5104-4058-cfae-7e3f239bd8b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultilayerPerceptron(\n",
              "  (model): Sequential(\n",
              "    (0): Linear(in_features=5000, out_features=5000, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=5000, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlBa8xaNMZgv"
      },
      "source": [
        "Let's loop over our test examples to see how well we are doing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGYn8CAoMTjX"
      },
      "source": [
        "all_gt_labels = []\n",
        "all_predict_labels = []\n",
        "\n",
        "for i, batch in enumerate(test_loader):\n",
        "    batch_inputs = batch[0].to(device)\n",
        "    batch_labels = batch[1].to(device)\n",
        "\n",
        "    outputs = model.forward(batch_inputs) # Remember you have probability here, need to get labels\n",
        "    out_labels = torch.argmax(outputs, dim=1).detach()\n",
        "\n",
        "    # Let's save both GT and Prected labels for the Acuracy, F1-Score Calculation\n",
        "    all_gt_labels.extend(batch_labels.tolist())\n",
        "    all_predict_labels.extend(out_labels.tolist())\n",
        "    # print(out_labels)\n",
        "    # break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_gt_labels), len(all_predict_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acXXsasJUnCo",
        "outputId": "36038c34-b9e2-4f39-be5a-51ae33c51763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score"
      ],
      "metadata": {
        "id": "fGWKTa2WUEu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_f1 = f1_score(all_gt_labels, all_predict_labels, average='macro')\n",
        "test_acc = accuracy_score(all_gt_labels, all_predict_labels)\n",
        "\n",
        "print(\"F1 Score : \", test_f1)\n",
        "print(\"Accuracy Score : \", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s70_4PxYV6OW",
        "outputId": "9bec79bb-9ba7-45b9-fe32-6eaa95b32234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score :  0.8299176801571961\n",
            "Accuracy Score :  0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(all_gt_labels, all_predict_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkLAGMa6WWmN",
        "outputId": "982b73e7-da0b-471b-aa7a-08e83dacf225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "[[202  44]\n",
            " [ 41 213]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Excercise\n",
        "\n",
        "\n",
        "\n",
        "*   **Add Extra Hidden Layer**: Currently we have only one hidden/linear layer in the model. Modify it, by adding one more hidden/linear layer. You might have to incorporate another activation function also.\n",
        "*   **Use Of Validation Set**: We have not used Validation set you should use validation set and monitors loss over epochs and stop training when loss keep increasing for continious 3 epochs\n",
        "*   **Save output**: In practice, we need each test sentences and it's predicted output and ground truth label. Find a way to save model's output in a `csv` file having columns `text`, `label` (for ground truth) and `prediction` (for predcited output).\n",
        "*   **Loss vs Epoch Plot**: It is always good practice to plot training and validation loss in a plot with respect to epoch to visually analyze the training process. Plot it, where epoch is X-axis and loss is Y-axis\n",
        "*   **Using Embedding Layer**: Current setup in not optimal because vocabulary size is large and needs a very large projection. We could reduce this by adding an Embedding layer. Incorporate Embedding layer into your code. Emedding could learned by two different ways\n",
        "  * Learn from scratch\n",
        "  * Use pre-trained embedding like `word2vec`\n",
        "\n",
        "  Implement both, take inspiration from https://colab.research.google.com/drive/1WUy4G2SsoLelrZDkO2I0v9tHx9x27NJK?usp=sharing#scrollTo=4wv875jUYtBD\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Note that all excercises are very important and will help you in the Assignment 2. I will ask submission in particular format and these help you in getting that.**\n"
      ],
      "metadata": {
        "id": "lnYoAmyCZ7UE"
      }
    }
  ]
}